
Syllabus


==== Math 457 Introduction to Statistical Learning. Fall 2021.====
Binghamton University 

  * Instructor: Vladislav Kargin
  * Office: WH-136
  * Meeting time and location: MWF 8:00 - 9:30 am at OH-G102.
  * Office hours: MWF 9:45 - 10:30 (in person, office WH136), Tue 4:00PM - 5:00PM (via Zoom, ID 949 5616 9870), or by appointment

** This course is a 4-credit course, which means that in addition to the scheduled lectures/discussions,
students are expected to do at least 9.5 hours of course-related work each week during the
semester. This includes things like: completing assigned readings, participating in lab sessions,
studying for tests and examinations, preparing written assignments, completing internship or
clinical placement requirements, and other tasks that must be completed to earn credit in the 
course. **

=== Prerequisite ===

  * Scientific programming in a language such as R, Matlab, or Python.
  * Linear regression and its inference
  * Matrix algebra, preferably including orthogonality, eigenvalues and eigenvectors, and singular value decomposition.

=== Description ===

This course is a survey of statistical learning methods. It will cover major statistical learning methods and concepts for both supervised and unsupervised learning. Topics covered include regression methods with sparsity or other regularizations, model selection, introduction to classification, including discriminant analysis, logistic regression, support vector machines, and kernel methods, nonlinear methods, clustering, decision trees, random forest, boosting and ensemble learning, deep learning



=== Learning Outcomes === 

Students will learn how and when to apply statistical learning techniques, their comparative strengths and weaknesses, and how to critically evaluate the performance of learning algorithms. Students completing this course should be able to 

  * process and visualize different data types,
  * apply basic statistical learning methods to build predictive models or perform exploratory analysis
  * have basic understanding of the underlying mechanism of predictive models and evaluate and interpret such models,
  * properly tune, select and validate statistical learning models,
  * use analytical tools and software widely used in practice,
  * work both independently and in a team to solve problems, and
  * learn to present and communicate the findings effectively.

=== Recommended Texts ===

  * James, Witten, Hastie and Tibshirani, 2021. "An Introduction to Statistical Learning with Applications in R.2nd edition" The Book Home Page is at "http://www-bcf.usc.edu/~gareth/ISL/index.html". A pdf file can be downloaded from this page. 


/*
<li><p>Hastie, Trevor, Tibshirani, Robert, and Friedman, J. H. 2009. The elements of statistical learning: Data mining, inference, and prediction. New York, NY: Springer New York.</p>
</li>
<li><p>Hastie, Trevor, Tibshirani, Robert, and Wainwright, Martin. Statistical Learning with Sparsity: The Lasso and Generalizations. Chapman and Hall/CRC; 1 edition (May 7, 2015). A pdf file of the first edition can be downloaded from "https://web.stanford.edu/~hastie/StatLearnSparsity/".  

</li>
<li><p>BÃ¼hlmann, Peter, and van de Geer, Sara. Statistics for High-Dimensional Data. Springer-Verlag Berlin Heidelberg.</p>
</li>
<li><p>Boyd, Stephen, and Vandenberghe, Lieven. Convex Optimization. Cambridge University Press. The <a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">PDF</a> file of the book can be downloaded for free.</p>
</li>
</ul>
*/


=== Online resources === 
There is a course taught by Hastie and Tibshirani using the first edition of their book. This Course is available at [[https://www.edx.org/course/statistical-learning|edx]]. The course is not free, however the videos and some other resources are available to auditors. The videos can also be obtained at [[https://www.dataschool.io/15-hours-of-expert-machine-learning-videos/|this website]] through playlist links.



=== Software ===

We will use R and R Markdown for this class. The IDE for R, RStudio can be downloaded from [[https://www.rstudio.com/products/rstudio/download/|here]].



=== Piazza===

We will use Piazza ("http://piazza.com/") for communication. All announcements will be sent to the class using Piazza.

=== Gradescope ===
We will use Gradescope ("https://www.gradescope.com/") to submit and grade homework. This will allow the instructor to efficient grade all the work and give feedback in a timely manner.

=== Mycourses ===

Mycourses ("http://mycourses.binghamton.edu") will only be used occasionally for recording grades on assignments and exams and for distributing solutions.  

=== Homework Policy === 
Homework will be assigned approximately bi-weekly. 
It is expected that homework is prepared using R Markdown or LaTeX. Handwritten homework is not accepted. There will be a deduction of 15% of the grade for each day homework assignment is late (the final grade for a late homework that is N days late will be 0.85^N times the real grade). Homeworks may be discussed with classmates but must be written and submitted individually.

=== Midterm Exam === 
A midterm exam focusing on the theoretical part of the course will be  administered in November. 

=== Project ===
A group project will be assigned to each student (2 - 4 students in a group). Successful completion of the project includes an initial report, a presentation and a final report.



=== Grading ===
  * Homework (40%): homework is assigned biweekly.
  * Midterm exam (30%):
  * Project (30%)
  * Lecture attendance and participation -- possible bonus of up to 3% according to the instructor judgement. 





/*
<h2>Data Analysis Contest</h2>
<p>Students will compete against each other in a Data Analysis Contest. The competition will begin on Tuesday, Feburary 20 and can be completed in teams of 2 &ndash; 4 members. Grades will be based upon a progress report and a final report (one per team) as well as the contest results. Further details about the contest along with specific grading criteria will be given in a separate document and discussed in class.</p>
*/






=== Tentative schedule ===

| Midterm | Nov 22 |
| Project Proposal | due Nov 24 |
| Preliminary report  | due Dec 3 |
| Project presentations | December 6, 8, 10 |
| Final Report | due December 13 |

/* 30 person/3 = 10 groups. Every group presentation: 20 minutes, so 4 groups in 1 class so 3 classes needed. */



/*

Students are expected to write homework in LaTex. For users with no experience with LaTex, I suggest using the cloud LaTex editing service at "https://www.overleaf.com/".

<table id="schedule">
<tr class="r1"><td class="c1">Lecture </td><td class="c2"> Week </td><td class="c3"> Date             </td><td class="c4"> Module                                </td><td class="c5"> Tentative Topic                                     </td><td class="c6"> Assigned </td><td class="c7"> Due  </td></tr>
<tr class="r2"><td class="c1">1       </td><td class="c2"> 1    </td><td class="c3"> Jan-21, Tuesday  </td><td class="c4"> I. Regression with Sparsity           </td><td class="c5"> Introduction                                        </td><td class="c6"> HW0      </td><td class="c7">      </td></tr>
<tr class="r3"><td class="c1">2       </td><td class="c2">      </td><td class="c3"> Jan-23, Thursday </td><td class="c4">                                       </td><td class="c5"> MSE &amp; Least Square                                  </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r4"><td class="c1">3       </td><td class="c2"> 2    </td><td class="c3"> Jan-28, Tuesday  </td><td class="c4">                                       </td><td class="c5"> Ridge Regression                                    </td><td class="c6"> HW1      </td><td class="c7"> HW0  </td></tr>
<tr class="r5"><td class="c1">4       </td><td class="c2">      </td><td class="c3"> Jan-30, Thursday </td><td class="c4">                                       </td><td class="c5"> Sparse Regression I                                 </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r6"><td class="c1">5       </td><td class="c2"> 3    </td><td class="c3"> Feb-4, Tuesday   </td><td class="c4">                                       </td><td class="c5"> Sparse Regression II                                </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r7"><td class="c1">6       </td><td class="c2">      </td><td class="c3"> Feb-6, Thursday  </td><td class="c4">                                       </td><td class="c5"> Graphical Models &amp; Compressed Sensing               </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r8"><td class="c1">7       </td><td class="c2"> 4    </td><td class="c3"> Feb-11, Tuesday  </td><td class="c4"> II. Pipeline for Statistical Learning </td><td class="c5"> Model Selection and Assessment                      </td><td class="c6"> HW 2     </td><td class="c7"> HW 1 </td></tr>
<tr class="r9"><td class="c1">8       </td><td class="c2">      </td><td class="c3"> Feb-13, Thursday </td><td class="c4">                                       </td><td class="c5"> Model Validation                                    </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r10"><td class="c1">9       </td><td class="c2"> 5    </td><td class="c3"> Feb-18, Tuesday  </td><td class="c4">                                       </td><td class="c5"> Case Studies &amp; Logistic Regression                  </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r11"><td class="c1">10      </td><td class="c2">      </td><td class="c3"> Feb-20, Thursday </td><td class="c4"> III. Classification Methods           </td><td class="c5"> LR Computing &amp; Other GLMs                           </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r12"><td class="c1">11      </td><td class="c2"> 6    </td><td class="c3"> Feb-25, Tuesday  </td><td class="c4">                                       </td><td class="c5"> Sparse GLM &amp; Bayes Classifier                       </td><td class="c6"> HW 3     </td><td class="c7"> HW2  </td></tr>
<tr class="r13"><td class="c1">12      </td><td class="c2">      </td><td class="c3"> Feb-27, Thursday </td><td class="c4">                                       </td><td class="c5"> LDA                                                 </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r14"><td class="c1">13      </td><td class="c2"> 7    </td><td class="c3"> Mar-3, Tuesday   </td><td class="c4">                                       </td><td class="c5"> SVM I: linear SVM                                   </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r15"><td class="c1">NA      </td><td class="c2">      </td><td class="c3"> Mar-5, Thursday  </td><td class="c4">                                       </td><td class="c5"> NO CLASS                                       </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r16"><td class="c1">14      </td><td class="c2"> 8    </td><td class="c3"> Mar-10, Tuesday  </td><td class="c4">                                       </td><td class="c5"> SVM II: dual solution, kernel SVM                   </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r17"><td class="c1">15      </td><td class="c2">      </td><td class="c3"> Mar-12, Thursday </td><td class="c4"> IV. Nonlinear Methods                 </td><td class="c5"> Nonlinear I: RKHS, KRR, Kernel PCA                  </td><td class="c6"> HW 4     </td><td class="c7"> HW3  </td></tr>
<tr class="r18"><td class="c1">16      </td><td class="c2"> 9    </td><td class="c3"> Mar-17, Tuesday  </td><td class="c4">                                       </td><td class="c5"> Nonlinear II: Polynomial reg., smoothing, GAM, etc. </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r19"><td class="c1">17      </td><td class="c2">      </td><td class="c3"> Mar-19, Thursday </td><td class="c4">                                       </td><td class="c5"> Neural Network                                      </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r20"><td class="c1">18      </td><td class="c2"> 10   </td><td class="c3"> Mar-24, Tuesday  </td><td class="c4"> V. Dimension Reduction                </td><td class="c5"> Dimension Reduction I: PCA-1                        </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r21"><td class="c1">19      </td><td class="c2">      </td><td class="c3"> Mar-26, Thursday </td><td class="c4">                                       </td><td class="c5"> Dimension Reduction I: PCA-2                        </td><td class="c6"> HW 5     </td><td class="c7"> HW4  </td></tr>
<tr class="r22"><td class="c1">20      </td><td class="c2"> 11   </td><td class="c3"> Mar-31, Tuesday  </td><td class="c4">                                       </td><td class="c5"> Dimension Reduction II: Extensions, NMF             </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r23"><td class="c1">21      </td><td class="c2">      </td><td class="c3"> Apr-2, Thursday  </td><td class="c4">                                       </td><td class="c5"> Dimension Reduction II: ICA, MDS                    </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r24"><td class="c1">NA      </td><td class="c2"> 12   </td><td class="c3"> Apr-7, Tuesday   </td><td class="c4">                                       </td><td class="c5"> NO CLASS                                      </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r25"><td class="c1">NA      </td><td class="c2">      </td><td class="c3"> Apr-9, Thursday  </td><td class="c4">                                       </td><td class="c5"> NO CLASS                                      </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r26"><td class="c1">22      </td><td class="c2"> 13   </td><td class="c3"> Apr-14, Tuesday  </td><td class="c4"> VI. Clustering                        </td><td class="c5"> Clustering I: K-means                               </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r27"><td class="c1">23      </td><td class="c2">      </td><td class="c3"> Apr-16, Thursday </td><td class="c4">                                       </td><td class="c5"> Clustering II: k-means, EM, HC                      </td><td class="c6"> HW 6     </td><td class="c7"> HW5  </td></tr>
<tr class="r28"><td class="c1">24      </td><td class="c2"> 14   </td><td class="c3"> Apr-21, Tuesday  </td><td class="c4">                                       </td><td class="c5"> Clustering III, HC; Trees                           </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r29"><td class="c1">25      </td><td class="c2">      </td><td class="c3"> Apr-23, Thursday </td><td class="c4">                                       </td><td class="c5"> Midterm Exam                                        </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r30"><td class="c1">26      </td><td class="c2"> 15   </td><td class="c3"> Apr-28, Tuesday  </td><td class="c4"> VII. Ensemble Methods                 </td><td class="c5"> Bagging; Random Forests                             </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r31"><td class="c1">27      </td><td class="c2">      </td><td class="c3"> Apr-30, Thursday </td><td class="c4">                                       </td><td class="c5"> Ensembles &amp; Boosting                                </td><td class="c6">          </td><td class="c7">      </td></tr>
<tr class="r32"><td class="c1">28      </td><td class="c2">      </td><td class="c3"> May-5, Tuesday   </td><td class="c4">                                       </td><td class="c5"> Gradient Boosting &amp; XGBoost                         </td><td class="c6">          </td><td class="c7"> HW 6 
</td></tr></table>
<div id="footer">
<div id="footer-text">
*/